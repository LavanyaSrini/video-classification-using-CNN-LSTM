{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import Convolution3D, MaxPooling3D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import applications\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.utils import shuffle\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.convolutional import (Conv2D, MaxPooling3D, Conv3D,\n",
    "    MaxPooling2D)\n",
    "from collections import deque\n",
    "import sys\n",
    "import glob,os\n",
    "from scipy.misc import imread,imresize\n",
    "from keras.models import model_from_json\n",
    "from os import listdir\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Input\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import TimeDistributed, Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, LSTM, Dense, TimeDistributed, InputLayer\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "import numpy as np\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.utils import np_utils, generic_utils\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "img_rows,img_cols,img_depth=16,16,5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_tr=[]          \n",
    "\n",
    "\n",
    "\n",
    "listing = os.listdir('ApplyEyeMakeup') \n",
    "\n",
    "for vid in listing:\n",
    "    vid = 'ApplyEyeMakeup/'+vid\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(vid)\n",
    "    fps = cap.get(5)\n",
    "    print(\"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps))\n",
    " \n",
    "\n",
    "    for k in range(5):\n",
    "        ret, frame = cap.read()\n",
    "        frame=cv2.resize(frame,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frames.append(gray)\n",
    "\n",
    "        \n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    input=np.array(frames)\n",
    "\n",
    "    print(input.shape)\n",
    "    ipt=np.rollaxis(np.rollaxis(input,2,0),2,0)\n",
    "    print(ipt.shape)\n",
    "\n",
    "    X_tr.append(ipt)\n",
    "\n",
    "\n",
    "\n",
    "listing2 = os.listdir('ApplyLipstick')\n",
    "for vid2 in listing2:\n",
    "    vid2 = 'ApplyLipstick/'+vid2\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(vid2)\n",
    "    fps = cap.get(5)\n",
    "    print(\"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps))\n",
    "\n",
    "    for k in range(5):\n",
    "        ret, frame = cap.read()\n",
    "        frame=cv2.resize(frame,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frames.append(gray)\n",
    "\n",
    "        \n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    input=np.array(frames)\n",
    "\n",
    "    print(input.shape)\n",
    "    ipt=np.rollaxis(np.rollaxis(input,2,0),2,0)\n",
    "    print(ipt.shape)\n",
    "\n",
    "    X_tr.append(ipt)\n",
    "\n",
    "\n",
    "\n",
    "listing3 = os.listdir('Archery') \n",
    "\n",
    "for vid3 in listing3:\n",
    "    vid3 = 'Archery/'+vid3\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(vid3)\n",
    "    fps = cap.get(5)\n",
    "    print(\"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps))\n",
    "\n",
    "    for k in range(5):\n",
    "        ret, frame = cap.read()\n",
    "        frame=cv2.resize(frame,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frames.append(gray)\n",
    "\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    input=np.array(frames)\n",
    "\n",
    "    print(input.shape)\n",
    "    ipt=np.rollaxis(np.rollaxis(input,2,0),2,0)\n",
    "    print(ipt.shape)\n",
    "\n",
    "    X_tr.append(ipt)\n",
    "\n",
    "\n",
    "\n",
    "listing4 = os.listdir('BabyCrawling') \n",
    "\n",
    "for vid4 in listing4:\n",
    "    vid4 = 'BabyCrawling/'+vid4\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(vid4)\n",
    "    fps = cap.get(5)\n",
    "    print(\"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps))\n",
    "\n",
    "    for k in range(5):\n",
    "        ret, frame = cap.read()\n",
    "        frame=cv2.resize(frame,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frames.append(gray)\n",
    "\n",
    "        \n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    input=np.array(frames)\n",
    "\n",
    "    print(input.shape)\n",
    "    ipt=np.rollaxis(np.rollaxis(input,2,0),2,0)\n",
    "    print(ipt.shape)\n",
    "\n",
    "    X_tr.append(ipt)\n",
    "\n",
    "\n",
    " \n",
    "listing5 = os.listdir('BalanceBeam') \n",
    "\n",
    "for vid5 in listing5:\n",
    "    vid5 = 'BalanceBeam/'+vid5\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(vid5)\n",
    "    fps = cap.get(5)\n",
    "    print(\"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps))\n",
    "\n",
    "    for k in range(5):\n",
    "        ret, frame = cap.read()\n",
    "        frame=cv2.resize(frame,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frames.append(gray)\n",
    "\n",
    "        \n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    input=np.array(frames)\n",
    "\n",
    "    print(input.shape)\n",
    "    ipt=np.rollaxis(np.rollaxis(input,2,0),2,0)\n",
    "    print(ipt.shape)\n",
    "\n",
    "    X_tr.append(ipt)\n",
    " \n",
    "\n",
    "#Reading walking action class \n",
    "\n",
    "listing6 = os.listdir('BandMarching') \n",
    "\n",
    "for vid6 in listing6:\n",
    "    vid6 = 'BandMarching/'+vid6\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(vid6)\n",
    "    fps = cap.get(5)\n",
    "    print(\"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps))\n",
    "\n",
    "    for k in range(5):\n",
    "        ret, frame = cap.read()\n",
    "        frame=cv2.resize(frame,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frames.append(gray)\n",
    "\n",
    "        \n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    input=np.array(frames)\n",
    "\n",
    "    print(input.shape)\n",
    "    ipt=np.rollaxis(np.rollaxis(input,2,0),2,0)\n",
    "    print(ipt.shape)\n",
    "\n",
    "    X_tr.append(ipt)\n",
    "\n",
    "\n",
    "\n",
    "X_tr_array = np.array(X_tr)   \n",
    "num_samples = len(X_tr_array)\n",
    "print ('num_samples',num_samples)\n",
    "\n",
    "\n",
    "\n",
    "label=np.ones((num_samples,),dtype = int)\n",
    "label[0:100]= 0\n",
    "label[100:199] = 1\n",
    "label[199:299] = 2\n",
    "label[299:399] = 3\n",
    "label[399:499]= 4\n",
    "label[499:] = 5\n",
    "\n",
    "\n",
    "train_data = [X_tr_array,label]\n",
    "\n",
    "(X_train, y_train) = (train_data[0],train_data[1])\n",
    "print('X_Train shape:', X_train.shape)\n",
    "\n",
    "train_set = np.zeros((num_samples, 1, img_rows,img_cols,img_depth))\n",
    "\n",
    "for h in range(num_samples):\n",
    "    train_set[h][0][:][:][:]=X_train[h,:,:,:]\n",
    "train_set=train_set.reshape(num_samples,img_depth,img_rows,img_cols,1)\n",
    "\n",
    "patch_size =5    \n",
    "\n",
    "print(train_set.shape, 'train samples')\n",
    "\n",
    "\n",
    "batch_size = 30\n",
    "nb_classes = 6\n",
    "nb_epoch =500\n",
    "\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "print(Y_train)\n",
    "\n",
    "\n",
    "nb_filters = [32, 32]\n",
    "\n",
    "\n",
    "nb_pool = [3, 3]\n",
    "\n",
    "\n",
    "nb_conv = [5,5]\n",
    "\n",
    "\n",
    "\n",
    "train_set = train_set.astype('float32')\n",
    "\n",
    "train_set -= np.mean(train_set)\n",
    "\n",
    "train_set /=np.max(train_set)\n",
    "print(train_set)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model=Sequential()\n",
    "model.add(TimeDistributed(Convolution2D(32,(7,7),strides=(2,2),activation='relu',padding='same'),input_shape=(patch_size, img_rows, img_cols,1)))\n",
    "model.add(TimeDistributed(Convolution2D(32,(3,3),init=\"he_normal\",activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2,2),strides=(1,1))))\n",
    "model.add(TimeDistributed(Convolution2D(64,(3,3),padding='same',activation='relu')))\n",
    "model.add(TimeDistributed(Convolution2D(64,(3,3),padding='same',activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2,2),strides=(1,1))))\n",
    "model.add(TimeDistributed(Convolution2D(128,(3,3),padding='same',activation='relu')))\n",
    "model.add(TimeDistributed(Convolution2D(128,(3,3),padding='same',activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2,2),strides=(1,1))))\n",
    "model.add(TimeDistributed(Convolution2D(256,(3,3),padding='same',activation='relu')))\n",
    "model.add(TimeDistributed(Convolution2D(256,(3,3),padding='same',activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2,2),strides=(1,1))))\n",
    "model.add(TimeDistributed(Convolution2D(512,(3,3),padding='same',activation='relu')))\n",
    "model.add(TimeDistributed(Convolution2D(512,(3,3),padding='same',activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2,2),strides=(1,1))))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(256, return_sequences=False, dropout=0.5))\n",
    "model.add(Dense(nb_classes,activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['mse', 'accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "X_train_new, X_val_new, y_train_new,y_val_new =  train_test_split(train_set, Y_train)#, test_size=0.1)#, random_state=4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hist = model.fit(X_train_new, y_train_new, validation_data=(X_val_new,y_val_new),batch_size=batch_size, nb_epoch = nb_epoch,shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "score = model.evaluate(X_val_new, y_val_new, batch_size=batch_size)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loss=hist.history['loss']\n",
    "val_loss=hist.history['val_loss']\n",
    "train_acc=hist.history['acc']\n",
    "val_acc=hist.history['val_acc']\n",
    "xc=range(500)\n",
    "\n",
    "plt.figure(1,figsize=(7,5))\n",
    "plt.plot(xc,train_loss)\n",
    "plt.plot(xc,val_loss)\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('train_loss vs val_loss')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'])\n",
    "print(plt.style.available )\n",
    "plt.style.use(['classic'])\n",
    "\n",
    "plt.figure(2,figsize=(7,5))\n",
    "plt.plot(xc,train_acc)\n",
    "plt.plot(xc,val_acc)\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('train_acc vs val_acc')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'],loc=4)\n",
    "\n",
    "plt.style.use(['classic'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
